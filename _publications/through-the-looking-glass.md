---
title: "Through the Looking Glass: Learning to Attribute Synthetic Text Generated by Language Models"
---
[Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume](https://aclanthology.org/2021.eacl-main.155.pdf) **(EACL 2021)**

***Shaoor Munir**, Brishna Batool, Zubair Shafiq, Padmini Srinivasan, Fareed Zaffar*

# Abstract
Given the potential misuse of recent advances in synthetic text generation by language models (LMs), it is important to have the capacity to attribute authorship of synthetic text. While stylometric organic (i.e., human written) authorship attribution has been quite successful, it is unclear whether similar approaches can be used to attribute a synthetic text to its source LM. We address this question with the key insight that synthetic texts carry subtle distinguishing marks inherited from their source LM and that these marks can be leveraged by machine learning (ML) algorithms for attribution. We propose and test several ML-based attribution methods. Our best attributor built using a fine-tuned version of XLNet (XLNet-FT) consistently achieves excellent accuracy scores (91% to near perfect 98%) in terms of attributing the parent pre-trained LM behind a synthetic text. Our experiments show promising results across a range of experiments where the synthetic text may be generated using pre-trained LMs, fine-tuned LMs, or by varying text generation parameters.